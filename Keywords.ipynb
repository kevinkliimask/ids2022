{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bec090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the data\n",
    "\n",
    "We will start off with importing all the necessary packages and the data.\n",
    "After looking at the data manually, we saw that 6 rows were 'broken' so to say with a lot of misaligned columns, so we decided to skip them.\n",
    "We will be using the selected columns from the report."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555fe7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = pd.read_csv('keywords.csv', low_memory=False)\n",
    "movies_df = pd.read_csv('movies_metadata.csv',skiprows=[19730, 19731, 29503, 29504, 35587, 35588], usecols=['id', 'vote_average', 'genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing data\n",
    "\n",
    "First off we will be converting the **JSON** formats of columns **'genres'** and **'keywords'** to a list format using the help of `ast.literal_eval()`,\n",
    "which helps to parse the columns' objects into the desired type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "movies_df['genres'] = movies_df['genres'].apply(lambda genres_list: [genres['name'] for genres in ast.literal_eval(genres_list)])\n",
    "\n",
    "keywords_df['keywords'] = keywords_df['keywords'].apply(lambda keywords_list: [keywords['name'] for keywords in ast.literal_eval(keywords_list)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mvies and keywords dataframes will be merged by their common column, **'id'**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd258f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           id                                           keywords  \\\n0         862  [jealousy, toy, boy, friendship, friends, riva...   \n1        8844  [board game, disappearance, based on children'...   \n2       15602  [fishing, best friend, duringcreditsstinger, o...   \n3       31357  [based on novel, interracial relationship, sin...   \n4       11862  [baby, midlife crisis, confidence, aging, daug...   \n...       ...                                                ...   \n46473  439050                                      [tragic love]   \n46474  111109                              [artist, play, pinoy]   \n46475   67758                                                 []   \n46476  227506                                                 []   \n46477  461257                                                 []   \n\n                             genres  vote_average  \n0       [Animation, Comedy, Family]           7.7  \n1      [Adventure, Fantasy, Family]           6.9  \n2                 [Romance, Comedy]           6.5  \n3          [Comedy, Drama, Romance]           6.1  \n4                          [Comedy]           5.7  \n...                             ...           ...  \n46473               [Drama, Family]           4.0  \n46474                       [Drama]           9.0  \n46475     [Action, Drama, Thriller]           3.8  \n46476                            []           0.0  \n46477                            []           0.0  \n\n[46478 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keywords</th>\n      <th>genres</th>\n      <th>vote_average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>7.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>[board game, disappearance, based on children'...</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>6.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15602</td>\n      <td>[fishing, best friend, duringcreditsstinger, o...</td>\n      <td>[Romance, Comedy]</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>[based on novel, interracial relationship, sin...</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>[baby, midlife crisis, confidence, aging, daug...</td>\n      <td>[Comedy]</td>\n      <td>5.7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46473</th>\n      <td>439050</td>\n      <td>[tragic love]</td>\n      <td>[Drama, Family]</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>46474</th>\n      <td>111109</td>\n      <td>[artist, play, pinoy]</td>\n      <td>[Drama]</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>46475</th>\n      <td>67758</td>\n      <td>[]</td>\n      <td>[Action, Drama, Thriller]</td>\n      <td>3.8</td>\n    </tr>\n    <tr>\n      <th>46476</th>\n      <td>227506</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>46477</th>\n      <td>461257</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>46478 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = keywords_df.merge(movies_df, on='id')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will do some data cleaning. We will remove movies with:\n",
    "\n",
    "- No genres or keywords\n",
    "- 0 vote_average"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of movies before performing all cleaning operations: 46478\n",
      "The number of movies after performing all cleaning operations: 30012\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of movies before performing all cleaning operations: {len(data)}')\n",
    "\n",
    "data.drop(data[(data['genres'].map(lambda genres: len(genres)) == 0) | (data['keywords'].map(lambda keywords: len(keywords)) == 0)].index, inplace=True)\n",
    "data.drop(data[data['vote_average'] == 0.0].index, inplace=True)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f'The number of movies after performing all cleaning operations: {len(data)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting data\n",
    "\n",
    "Firstly, we will split the data's features into variable **X** and the ratings into variable **y**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "y = data.loc[:, 'vote_average']\n",
    "X = data.loc[:, ['keywords', 'genres']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                keywords  \\\n0      [jealousy, toy, boy, friendship, friends, riva...   \n1      [board game, disappearance, based on children'...   \n2      [fishing, best friend, duringcreditsstinger, o...   \n3      [based on novel, interracial relationship, sin...   \n4      [baby, midlife crisis, confidence, aging, daug...   \n...                                                  ...   \n30007  [revenge, murder, serial killer, new york city...   \n30008                                      [blair witch]   \n30009  [witch, mythology, legend, serial killer, mock...   \n30010                                      [tragic love]   \n30011                              [artist, play, pinoy]   \n\n                             genres  \n0       [Animation, Comedy, Family]  \n1      [Adventure, Fantasy, Family]  \n2                 [Romance, Comedy]  \n3          [Comedy, Drama, Romance]  \n4                          [Comedy]  \n...                             ...  \n30007   [Horror, Mystery, Thriller]  \n30008             [Mystery, Horror]  \n30009                      [Horror]  \n30010               [Drama, Family]  \n30011                       [Drama]  \n\n[30012 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keywords</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n      <td>[Animation, Comedy, Family]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[board game, disappearance, based on children'...</td>\n      <td>[Adventure, Fantasy, Family]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[fishing, best friend, duringcreditsstinger, o...</td>\n      <td>[Romance, Comedy]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[based on novel, interracial relationship, sin...</td>\n      <td>[Comedy, Drama, Romance]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[baby, midlife crisis, confidence, aging, daug...</td>\n      <td>[Comedy]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30007</th>\n      <td>[revenge, murder, serial killer, new york city...</td>\n      <td>[Horror, Mystery, Thriller]</td>\n    </tr>\n    <tr>\n      <th>30008</th>\n      <td>[blair witch]</td>\n      <td>[Mystery, Horror]</td>\n    </tr>\n    <tr>\n      <th>30009</th>\n      <td>[witch, mythology, legend, serial killer, mock...</td>\n      <td>[Horror]</td>\n    </tr>\n    <tr>\n      <th>30010</th>\n      <td>[tragic love]</td>\n      <td>[Drama, Family]</td>\n    </tr>\n    <tr>\n      <th>30011</th>\n      <td>[artist, play, pinoy]</td>\n      <td>[Drama]</td>\n    </tr>\n  </tbody>\n</table>\n<p>30012 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the data contains many **unique** keywords, we decided that we will only use movies with the most popular keywords for our learning model. We will count the occurences of keywords so we can select only movies with the most popular keywords."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'woman director': 2753,\n 'independent film': 1891,\n 'murder': 1278,\n 'based on novel': 803,\n 'sex': 679,\n 'musical': 675,\n 'violence': 650,\n 'nudity': 631,\n 'revenge': 614,\n 'biography': 604,\n 'suspense': 587,\n 'love': 559,\n 'female nudity': 553,\n 'sport': 525,\n 'police': 447,\n 'duringcreditsstinger': 438,\n 'sequel': 435,\n 'teenager': 434,\n 'friendship': 406,\n 'world war ii': 383,\n 'drug': 351,\n 'prison': 342,\n 'high school': 313,\n 'martial arts': 310,\n 'stand-up comedy': 309,\n 'rape': 304,\n 'suicide': 304,\n 'film noir': 299,\n 'kidnapping': 298,\n 'serial killer': 289,\n 'family': 286,\n 'monster': 282,\n 'alien': 279,\n 'silent film': 278,\n 'dystopia': 271,\n 'blood': 266,\n 'paris': 265,\n 'new york': 263,\n 'gay': 256,\n 'marriage': 250,\n 'christmas': 250,\n 'gore': 245,\n 'short': 245,\n 'death': 243,\n 'zombie': 241,\n 'london england': 235,\n 'gangster': 234,\n 'small town': 234,\n 'aftercreditsstinger': 231,\n 'prostitute': 230,\n 'detective': 229,\n 'romance': 226,\n 'male nudity': 226,\n 'vampire': 224,\n 'wedding': 221,\n 'robbery': 220,\n 'los angeles': 219,\n 'escape': 219,\n 'father son relationship': 217,\n 'dog': 214,\n 'holiday': 212,\n 'teacher': 209,\n 'magic': 206,\n 'hospital': 203,\n 'war': 201,\n 'remake': 200,\n 'jealousy': 194,\n 'based on true story': 193,\n 'ghost': 193,\n 'music': 192,\n 'doctor': 192,\n 'party': 190,\n 'island': 185,\n 'new york city': 181,\n 'japan': 181,\n 'daughter': 180,\n 'investigation': 178,\n 'money': 177,\n 'lgbt': 176,\n 'corruption': 176,\n 'spy': 176,\n 'homosexuality': 175,\n 'torture': 175,\n 'superhero': 174,\n 'coming of age': 172,\n 'adultery': 172,\n 'extramarital affair': 172,\n 'infidelity': 172,\n 'brother brother relationship': 170,\n 'nazis': 170,\n 'slasher': 168,\n 'friends': 167,\n 'supernatural': 166,\n 'wife husband relationship': 165,\n 'dark comedy': 164,\n 'lawyer': 163,\n 'scientist': 160,\n 'fight': 160,\n 'student': 159,\n 'based on comic': 159,\n 'france': 159,\n 'college': 157,\n 'secret': 155,\n 'post-apocalyptic': 154,\n 'england': 154,\n 'comedy': 154,\n 'love triangle': 152,\n 'hotel': 150,\n '3d': 150,\n 'dying and death': 149,\n 'lesbian': 148,\n 'surrealism': 148,\n 'time travel': 147,\n 'soldier': 146,\n 'politics': 146,\n 'writer': 146,\n 'anime': 146,\n 'gang': 145,\n 'school': 144,\n 'flashback': 143,\n 'witch': 141,\n 'hitman': 141,\n 'dream': 141,\n 'pregnancy': 140,\n 'future': 140,\n 'survival': 139,\n 'airplane': 138,\n 'beach': 138,\n 'obsession': 137,\n 'family relationships': 137,\n 'b movie': 137,\n 'relationship': 136,\n 'train': 135,\n 'best friend': 134,\n 'based on play or musical': 134,\n 'killer': 134,\n 'journalist': 134,\n 'mother daughter relationship': 133,\n 'divorce': 132,\n 'psychopath': 132,\n 'blackmail': 131,\n 'demon': 131,\n 'rescue': 128,\n 'children': 128,\n 'desert': 128,\n 'assassin': 126,\n 'criminal': 125,\n 'forest': 125,\n 'drama': 123,\n 'tv movie': 123,\n 'road movie': 120,\n 'romantic comedy': 119,\n 'mafia': 118,\n 'sheriff': 117,\n 'hostage': 116,\n 'reporter': 116,\n 'neighbor': 116,\n '1970s': 115,\n 'shootout': 115,\n 'explosion': 115,\n 'prostitution': 115,\n 'australia': 115,\n 'bollywood': 115,\n 'chase': 114,\n 'alcohol': 113,\n 'seduction': 113,\n 'brother sister relationship': 113,\n 'crime': 112,\n 'erotic movie': 112,\n 'robot': 112,\n 'gun': 111,\n 'satire': 111,\n 'new love': 110,\n 'competition': 110,\n 'singer': 110,\n 'father daughter relationship': 110,\n 'conspiracy': 109,\n 'road trip': 109,\n 'italy': 109,\n 'nightmare': 109,\n 'religion': 109,\n 'mexico': 108,\n 'sister sister relationship': 108,\n 'orphan': 107,\n 'racism': 107,\n 'priest': 107,\n 'army': 107,\n 'baby': 106,\n 'cult film': 106,\n 'africa': 106,\n 'cia': 106,\n 'animation': 106,\n \"love of one's life\": 106,\n 'fbi': 105,\n 'nurse': 105,\n 'betrayal': 103,\n 'village': 103,\n 'alcoholic': 103,\n 'widow': 102,\n 'summer': 102,\n 'horror': 102,\n 'motorcycle': 102,\n 'cat': 101,\n 'native american': 101,\n 'spaghetti western': 101,\n 'terrorist': 100,\n 'horse': 100,\n 'texas': 100,\n 'found footage': 100,\n 'hollywood': 99,\n 'rural setting': 99,\n 'jungle': 99,\n 'spoof': 98,\n 'gambling': 98,\n 'eroticism': 98,\n 'heist': 97,\n 'dancing': 97,\n 'neo-noir': 96,\n 'space': 96,\n 'california': 96,\n 'marijuana': 96,\n 'super powers': 95,\n 'restaurant': 95,\n 'thief': 94,\n 'ship': 93,\n 'castle': 93,\n 'funeral': 93,\n 'artist': 91,\n 'werewolf': 91,\n 'haunted house': 91,\n 'brazilian': 91,\n 'samurai': 90,\n 'historical figure': 89,\n 'assassination': 89,\n 'drug dealer': 89,\n 'undercover': 89,\n 'baseball': 89,\n 'dance': 89,\n 'car crash': 88,\n 'church': 88,\n 'rivalry': 87,\n 'mutant': 87,\n 'photographer': 86,\n 'bar': 86,\n 'fairy tale': 86,\n 'documentary': 86,\n 'kung fu': 86,\n 'professor': 85,\n 'helicopter': 85,\n 'disaster': 85,\n 'hero': 85,\n 'china': 84,\n 'depression': 84,\n 'fire': 84,\n 'canuxploitation': 84,\n 'pilot': 83,\n 'incest': 83,\n 'author': 83,\n 'vacation': 83,\n 'cancer': 83,\n '19th century': 82,\n 'amnesia': 82,\n 'curse': 82,\n 'mountain': 81,\n 'falling in love': 80,\n 'gold': 80,\n 'dinosaur': 80,\n 'teenage girl': 80,\n 'parent child relationship': 79,\n 'police officer': 79,\n 'nightclub': 79,\n 'wilderness': 79,\n 'usa': 79,\n 'princess': 78,\n 'experiment': 78,\n 'based on tv series': 78,\n 'based on video game': 77,\n 'car chase': 77,\n 'san francisco': 77,\n 'suicide attempt': 77,\n 'sexuality': 77,\n 'farm': 77,\n 'sword': 77,\n 'youth': 77,\n 'soccer': 76,\n 'paranoia': 76,\n 'psychiatrist': 76,\n 'dc comics': 76,\n 'female protagonist': 76,\n 'cold war': 76,\n 'concert': 75,\n 'snow': 75,\n 'battle': 75,\n 'russia': 74,\n 'dysfunctional family': 74,\n 'gay interest': 73,\n 'boat': 73,\n 'decapitation': 73,\n 'india': 73,\n 'musician': 73,\n 'mystery': 73,\n 'giallo': 73,\n 'alcoholism': 72,\n 'faith': 72,\n 'terrorism': 72,\n 'miniseries': 72,\n 'bank robbery': 71,\n 'bomb': 71,\n 'gunfight': 71,\n 'interview': 71,\n 'history': 71,\n 'gay relationship': 71,\n 'sadism': 70,\n 'halloween': 70,\n 'world war i': 70,\n 'insanity': 70,\n 'exploitation': 70,\n 'spaceship': 70,\n 'berlin': 70,\n 'mad scientist': 70,\n 'fbi agent': 69,\n 'twins': 69,\n 'waitress': 69,\n 'spain': 69,\n 'terror': 69,\n 'father': 69,\n 'pirate': 68,\n 'fantasy': 68,\n 'space travel': 68,\n 'prince': 68,\n 'comedian': 68,\n 'marvel comic': 68,\n 'hoodlum': 67,\n 'courtroom': 67,\n 'car': 67,\n 'astronaut': 67,\n 'kiss': 67,\n 'outlaw': 67,\n 'possession': 67,\n 'boy': 66,\n 'disappearance': 66,\n 'bank': 66,\n 'sword fight': 66,\n 'extreme violence': 66,\n 'on the run': 66,\n 'revolution': 66,\n 'secret agent': 66,\n 'alien invasion': 66,\n 'unsimulated sex': 66,\n 'germany': 66,\n 'based on young adult novel': 66,\n 'usa president': 65,\n 'travel': 65,\n 'car accident': 65,\n 'mother': 65,\n 'cyborg': 65,\n 'loneliness': 65,\n 'cop': 65,\n 'american football': 65,\n 'sister': 65,\n 'cult': 65,\n 'nature': 65,\n 'lesbian relationship': 64,\n 'melodrama': 64,\n 'thriller': 64,\n 'millionaire': 63,\n 'chicago': 63,\n 'mother son relationship': 63,\n 'organized crime': 63,\n 'evil': 63,\n 'civil war': 63,\n 'virgin': 63,\n 'casino': 62,\n '1960s': 62,\n 'river': 62,\n 'judge': 62,\n 'prisoner': 62,\n 'anthology': 62,\n 'wheelchair': 62,\n 'apartment': 62,\n 'japanese': 62,\n 'canada': 62,\n 'single mother': 61,\n 'winter': 61,\n 'parody': 61,\n 'stripper': 61,\n 'military': 61,\n 'mental illness': 61,\n 'cheating': 61,\n 'mask': 61,\n 'sea': 61,\n 'swimming pool': 61,\n 'classic noir': 61,\n 'animal': 61,\n 'deception': 60,\n 'immigrant': 60,\n 'mercenary': 60,\n 'circus': 60,\n 'shower': 60,\n 'stalker': 60,\n 'secret identity': 59,\n 'theft': 59,\n 'adoption': 59,\n 'fugitive': 59,\n 'submarine': 59,\n 'mockumentary': 59,\n 'airport': 59,\n 'cyberpunk': 59,\n 'british': 59,\n 'queen': 59,\n 'santa claus': 59,\n 'hallucination': 59,\n 'outer space': 59,\n 'brother': 59,\n 'blaxploitation': 59,\n 'dragon': 59,\n 'dancer': 59,\n 'experimental film': 59,\n 'government': 58,\n 'motel': 58,\n 'marriage crisis': 58,\n 'vigilante': 58,\n 'roommate': 58,\n 'male friendship': 58,\n 'vietnam war': 58,\n 'treasure': 57,\n 'mobster': 57,\n 'wealth': 57,\n 'painting': 57,\n 'computer': 57,\n 'femme fatale': 57,\n 'science': 57,\n 'android': 57,\n 'transformation': 57,\n 'teen movie': 57,\n 'scotland': 56,\n 'poison': 56,\n 'christian': 56,\n 'poverty': 56,\n 'con man': 56,\n 'based on true events': 56,\n 'single': 55,\n 'girlfriend': 55,\n 'hong kong': 55,\n 'private detective': 55,\n 'illness': 55,\n 'mistaken identity': 55,\n 'devil': 55,\n 'occult': 55,\n '1980s': 55,\n 'loss of father': 54,\n 'basketball': 54,\n 'virus': 54,\n 'shark': 54,\n 'slavery': 54,\n 'female friendship': 53,\n 'court case': 53,\n 'university': 53,\n 'fistfight': 53,\n 'ireland': 53,\n 'coming out': 53,\n 'art': 53,\n 'child abuse': 53,\n 'bullying': 53,\n 'newspaper': 53,\n 'adventure': 53,\n 'book': 53,\n 'adult animation': 53,\n 'slapstick': 53,\n 'political': 53,\n 'yakuza': 53,\n 'giant monster': 53,\n 'hammer horror': 53,\n 'shakespeare': 52,\n 'bank robber': 52,\n 'boxer': 52,\n 'tragedy': 52,\n 'politician': 52,\n 'grief': 52,\n 'stop motion': 52,\n 'lover': 52,\n 'jazz': 52,\n 'resistance': 52,\n 'cocaine': 52,\n 'actress': 52,\n 'surreal': 52,\n 'video nasty': 52,\n 'television': 51,\n 'memory': 51,\n 'moon': 51,\n 'space opera': 51,\n 'black and white': 51,\n 'vietnam': 51,\n 'blood splatter': 51,\n 'gay man': 51,\n 'knife': 51,\n 'inheritance': 50,\n 'debt': 50,\n 'king': 50,\n 'jewish': 50,\n 'trial': 50,\n 'treasure hunt': 50,\n 'imax': 50,\n 'isolation': 50,\n 'fear': 50,\n 'house': 50,\n 'mythology': 50,\n 'wife': 50,\n 'dracula': 49,\n 'child': 49,\n 'artificial intelligence': 49,\n 'weapon': 49,\n 'masturbation': 49,\n 'lie': 49,\n 'creature': 49,\n 'lovers': 49,\n 'kaiju': 49,\n 'lovesickness': 48,\n 'married couple': 48,\n 'forbidden love': 48,\n 'nun': 48,\n 'underdog': 48,\n 'loss of mother': 48,\n 'narration': 48,\n 'florida': 48,\n '1940s': 48,\n 'frankenstein': 48,\n 'training': 48,\n 'saving the world': 48,\n 'rome': 48,\n 'series of murders': 48,\n 'corpse': 48,\n 'video game': 48,\n 'haunting': 48,\n 'court': 47,\n 'actor': 47,\n 'homophobia': 47,\n 'fashion': 47,\n 'drug addiction': 47,\n 'birthday': 47,\n 'woods': 47,\n 'german': 47,\n 'rebel': 47,\n 'apocalypse': 47,\n 'sweden': 47,\n 'bible': 47,\n 'korea': 47,\n 'photography': 46,\n 'brutality': 46,\n 'voyeur': 46,\n 'alien life-form': 46,\n 'city': 46,\n 'guilt': 46,\n 'shipwreck': 46,\n 'career': 46,\n 'prisoners of war': 46,\n 'camping': 46,\n 'girl': 45,\n 'marriage proposal': 45,\n 'letter': 45,\n 'virtual reality': 45,\n 'knight': 45,\n 'angel': 45,\n 'black people': 45,\n 'boarding school': 45,\n 'mass murder': 45,\n 'teenage crush': 45,\n 'epic': 45,\n 'cannibal': 45,\n 'mansion': 45,\n 'greed': 45,\n 'punk': 45,\n 'illegal prostitution': 44,\n 'diner': 44,\n 'secret love': 44,\n 'pornography': 44,\n 'psychic': 44,\n 'dating': 44,\n 'lust': 44,\n 'good vs evil': 44,\n 'cowboy': 44,\n 'secretary': 44,\n 'loss of lover': 44,\n 'underwear': 44,\n 'cannibalism': 44,\n 'agent': 44,\n 'anarchic comedy': 44,\n 'taxi driver': 44,\n 'storm': 44,\n 'car race': 44,\n 'space marine': 44,\n 'street gang': 44,\n 'egypt': 44,\n 'brit noir': 44,\n 'spirit': 44,\n 'rock': 44,\n 'snake': 44,\n 'philippines': 44,\n 'taxi': 43,\n 'ocean': 43,\n 'celebrity': 43,\n 'royalty': 43,\n 'nazi germany': 43,\n 'theater': 43,\n 'science fiction': 43,\n 'based on manga': 43,\n 'singing': 43,\n 'adolescence': 43,\n 'christianity': 43,\n 'animal horror': 43,\n 'painter': 42,\n 'puberty': 42,\n 'unemployment': 42,\n 'bridge': 42,\n 'vietnam veteran': 42,\n 'strip club': 42,\n 'addiction': 42,\n 'aids': 42,\n 'water': 42,\n 'human experimentation': 42,\n 'becoming an adult': 42,\n 'camp': 42,\n 'jail': 42,\n 'bear': 42,\n 'italian': 42,\n 'jew': 42,\n 'hell': 42,\n 'mission': 42,\n 'french': 42,\n 'beer': 42,\n 'male female relationship': 42,\n 'sword and sorcery': 42,\n 'ninja': 42,\n 'showdown': 41,\n 'philosophy': 41,\n 'brothel': 41,\n 'new zealand': 41,\n 'sniper': 41,\n 'gothic': 41,\n 'museum': 41,\n 'heroin': 41,\n 'duel': 41,\n 'cemetery': 41,\n 'food': 41,\n 'pimp': 41,\n 'missing person': 41,\n 'las vegas': 41,\n 'maniac': 41,\n 'uncle': 40,\n 'hip-hop': 40,\n 'hacker': 40,\n 'russian': 40,\n 'voodoo': 40,\n 'kids': 40,\n 'crush': 40,\n 'radio': 40,\n 'home invasion': 40,\n 'journalism': 40,\n 'psychological thriller': 40,\n 'age difference': 40,\n 'espionage': 40,\n 'architect': 40,\n 'break-up': 40,\n 'animal attack': 40,\n 'one-night stand': 40,\n 'israel': 40,\n 'sexploitation': 40,\n 'ex-con': 39,\n 'subway': 39,\n 'psychologist': 39,\n 'individual': 39,\n 'amusement park': 39,\n 'puppet': 39,\n 'bounty hunter': 39,\n 'african american': 39,\n 'legend': 39,\n 'flying': 39,\n 'southern usa': 39,\n 'passion': 39,\n 'autism': 39,\n 'lake': 39,\n 'redemption': 39,\n 'unrequited love': 39,\n 'inventor': 39,\n 'manhattan, new york city': 39,\n 'thailand': 39,\n 'survivor': 39,\n 'undead': 39,\n 'airplane crash': 39,\n 'underwater': 39,\n 'archaeologist': 39,\n 'supernatural powers': 39,\n 'disney short': 39,\n 'midlife crisis': 38,\n 'poker': 38,\n 'fisherman': 38,\n 'poet': 38,\n 'bully': 38,\n 'celebration': 38,\n 'tattoo': 38,\n 'babysitter': 38,\n 'film making': 38,\n 'film director': 38,\n 'kingdom': 38,\n 'nanny': 38,\n 'ransom': 38,\n 'factory': 38,\n 'trapped': 38,\n 'madness': 38,\n 'journey': 38,\n 'identity': 38,\n '1950s': 38,\n 'chaos': 38,\n 'muslim': 38,\n 'cigarette smoking': 38,\n 'cabin': 38,\n 'model': 38,\n 'brazil': 38,\n 'bikini': 38,\n 'mumblegore': 38,\n 'xenophobia': 37,\n 'internet': 37,\n 'dystopic future': 37,\n 'accident': 37,\n 'opera': 37,\n 'summer camp': 37,\n 'sailor': 37,\n 'u.s. army': 37,\n 'volcano': 37,\n '1930s': 37,\n 'planned murder': 37,\n 'terminal illness': 37,\n 'mutation': 37,\n 'intelligence': 37,\n 'farmer': 37,\n 'anthropomorphism': 37,\n 'stranded': 37,\n 'ambition': 37,\n 'sherlock holmes': 37,\n 'massacre': 37,\n 'korean movie': 37,\n 'psychology': 36,\n 'cowardliness': 36,\n 'unsociability': 36,\n 'monkey': 36,\n 'coffin': 36,\n 'laboratory': 36,\n 'communism': 36,\n 'afterlife': 36,\n 'monk': 36,\n 'voyeurism': 36,\n 'pregnant': 36,\n 'single parent': 36,\n 'business man': 36,\n 'coma': 36,\n 'olympic games': 36,\n 'navy': 36,\n 'hypnosis': 36,\n 'carnival': 36,\n 'runaway': 36,\n 'ranch': 36,\n 'poetry': 36,\n 'song': 36,\n 'rock star': 36,\n 'soviet union': 36,\n 'exorcism': 36,\n 'beautiful woman': 36,\n 'war crimes': 36,\n 'young adult': 36,\n 'ballet': 36,\n 'shooting': 35,\n 'drug abuse': 35,\n 'hotel room': 35,\n 'police brutality': 35,\n 'talking animal': 35,\n 'police detective': 35,\n 'vision': 35,\n 'president': 35,\n 'pistol': 35,\n 'drug traffic': 35,\n 'upper class': 35,\n 'saloon': 35,\n 'movie star': 35,\n 'filmmaking': 35,\n 'policeman': 35,\n 'holocaust': 35,\n 'traitor': 35,\n 'washington d.c.': 35,\n 'pre-code': 35,\n 'sexual abuse': 35,\n 'rock and roll': 35,\n 'female homosexuality': 35,\n 'rain': 35,\n 'american': 35,\n 'economics': 35,\n 'south korea': 35,\n 'therapist': 34,\n 'maid': 34,\n 'double life': 34,\n 'ambush': 34,\n 'resurrection': 34,\n 'bodyguard': 34,\n 'smuggling': 34,\n 'general': 34,\n 'older man younger woman relationship': 34,\n 'communist': 34,\n 'jesus christ': 34,\n 'god': 34,\n 'bride': 34,\n 'boston': 34,\n 'rock band': 34,\n 'society': 34,\n 'orphanage': 34,\n 'drug use': 34,\n 'immortality': 34,\n 'power': 34,\n 'illegal drugs': 34,\n 'europe': 34,\n 'catholicism': 34,\n 'hitchhiker': 34,\n 'chainsaw': 34,\n 'cruelty': 34,\n 'couple': 34,\n 'memory loss': 34,\n 'mind control': 34,\n 'fighter': 34,\n 'swamp': 34,\n 'business': 33,\n 'son': 33,\n 'peasant': 33,\n 'mayor': 33,\n 'diamond': 33,\n 'ladykiller': 33,\n 'success': 33,\n 'nasa': 33,\n 'cinema': 33,\n 'stalking': 33,\n 'humiliation': 33,\n 'immigration': 33,\n 'tv show': 33,\n 'manipulation': 33,\n 'arranged marriage': 33,\n 'doppelganger': 33,\n 'indian lead': 33,\n 'bus': 33,\n 'new orleans': 33,\n 'capitalism': 33,\n 'french noir': 33,\n 'technology': 33,\n 'honeymoon': 33,\n 'music band': 33,\n 'asylum': 33,\n 'wrestling': 33,\n 'tokyo japan': 33,\n 'relationship problems': 33,\n 'infection': 33,\n 'widower': 32,\n 'wolf': 32,\n 'exotic island': 32,\n 'period drama': 32,\n 'south africa': 32,\n 'kids and family': 32,\n 'date': 32,\n 'feminism': 32,\n 'freedom': 32,\n 'diary': 32,\n 'undercover agent': 32,\n 'trauma': 32,\n 'little girl': 32,\n 'escape from prison': 32,\n 'propaganda': 32,\n 'earthquake': 32,\n 'highway': 32,\n 'disguise': 32,\n 'education': 32,\n 'surveillance': 32,\n 'sadness': 32,\n 'atomic bomb': 32,\n 'axe murder': 32,\n 'madrid': 32,\n 'juvenile delinquent': 32,\n 'ufo': 32,\n 'women': 32,\n 'drinking': 32,\n 'drunk': 32,\n 'delusion': 32,\n 'cover-up': 32,\n 'proto-slasher': 32,\n 'teen comedy': 32,\n 'ritual': 32,\n 'cheerleader': 32,\n 'drowning': 32,\n 'biker': 32,\n 'gothic horror': 32,\n 'charlie chan': 32,\n \"based on children's book\": 31,\n 'cuba': 31,\n 'falsely accused': 31,\n 'police operation': 31,\n 'love at first sight': 31,\n 'captain': 31,\n 'schizophrenia': 31,\n 'parallel world': 31,\n 'prophecy': 31,\n 'drug lord': 31,\n 'wish': 31,\n 'venice': 31,\n 'dirty cop': 31,\n 'new england': 31,\n 'heavy metal': 31,\n 'blindness': 31,\n 'apache': 31,\n 'shotgun': 31,\n 'older woman younger man relationship': 31,\n 'truck': 31,\n 'aviation': 31,\n 'mexican': 31,\n 'death of a friend': 31,\n 'mummy': 31,\n 'search': 31,\n 'witchcraft': 31,\n 'greece': 31,\n 'interracial relationship': 30,\n 'childhood': 30,\n 'pig': 30,\n 'victim': 30,\n 'u.s. navy': 30,\n 'danger': 30,\n 'cave': 30,\n 'gas station': 30,\n 'desire': 30,\n 'suspicion': 30,\n 'climbing': 30,\n 'hustler': 30,\n 'argentina': 30,\n 'countryside': 30,\n 'false identity': 30,\n 'black magic': 30,\n 'little boy': 30,\n 'childhood friends': 30,\n 'drunkenness': 30,\n 'turkey': 30,\n 'arizona': 30,\n 'tourist': 30,\n 'war veteran': 30,\n 'nerd': 30,\n 'rock music': 30,\n 'attack': 30,\n 'gypsy': 30,\n 'spider': 30,\n 'sacrifice': 30,\n 'lesbian sex': 30,\n 'cell phone': 30,\n 'aging': 29,\n \"new year's eve\": 29,\n 'mission of murder': 29,\n 'teenage boy': 29,\n 'loss of virginity': 29,\n 'disabled': 29,\n 'underground': 29,\n 'fascism': 29,\n 'gunslinger': 29,\n 'filmmaker': 29,\n 'homeless person': 29,\n 'swordplay': 29,\n 'police corruption': 29,\n 'catholic': 29,\n 'spacecraft': 29,\n 'telekinesis': 29,\n 'salesman': 29,\n 'officer': 29,\n 'bondage': 29,\n 'stranger': 29,\n 'cattle': 29,\n 'combat': 29,\n 'flying saucer': 29,\n 'night': 29,\n 'murderer': 29,\n 'fate': 29,\n 'justice': 29,\n 'surfing': 29,\n 'end of the world': 29,\n 'convict': 29,\n 'execution': 29,\n 'fraud': 29,\n 'godzilla': 29,\n 'love affair': 29,\n 'rifle': 29,\n 'undercover cop': 29,\n 'boyfriend': 29,\n 'zombie apocalypse': 29,\n 'malayalam': 29,\n 'alaska': 28,\n 'karate': 28,\n 'conflict': 28,\n 'medicine': 28,\n 'fish': 28,\n 'hawaii': 28,\n 'miracle': 28,\n 'prank': 28,\n ...}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_counts = {}\n",
    "\n",
    "for word_list in X['keywords']:\n",
    "    for word in word_list:\n",
    "        if word in keyword_counts:\n",
    "            keyword_counts[word] += 1\n",
    "        else:\n",
    "            keyword_counts[word] = 1\n",
    "\n",
    "# sorting the dictionary\n",
    "keyword_counts = {key: value for key, value in sorted(keyword_counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "keyword_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We decided to use the top 1000 most popular keywords for our learning model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                keywords  \\\n0          [jealousy, boy, friendship, friends, rivalry]   \n1              [disappearance, based on children's book]   \n2                    [best friend, duringcreditsstinger]   \n3      [based on novel, interracial relationship, sin...   \n4      [baby, midlife crisis, aging, daughter, mother...   \n...                                                  ...   \n30007    [revenge, murder, serial killer, new york city]   \n30008                                                 []   \n30009  [witch, mythology, legend, serial killer, mock...   \n30010                                                 []   \n30011                                           [artist]   \n\n                             genres  \n0       [Animation, Comedy, Family]  \n1      [Adventure, Fantasy, Family]  \n2                 [Romance, Comedy]  \n3          [Comedy, Drama, Romance]  \n4                          [Comedy]  \n...                             ...  \n30007   [Horror, Mystery, Thriller]  \n30008             [Mystery, Horror]  \n30009                      [Horror]  \n30010               [Drama, Family]  \n30011                       [Drama]  \n\n[30012 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keywords</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[jealousy, boy, friendship, friends, rivalry]</td>\n      <td>[Animation, Comedy, Family]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[disappearance, based on children's book]</td>\n      <td>[Adventure, Fantasy, Family]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[best friend, duringcreditsstinger]</td>\n      <td>[Romance, Comedy]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[based on novel, interracial relationship, sin...</td>\n      <td>[Comedy, Drama, Romance]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[baby, midlife crisis, aging, daughter, mother...</td>\n      <td>[Comedy]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30007</th>\n      <td>[revenge, murder, serial killer, new york city]</td>\n      <td>[Horror, Mystery, Thriller]</td>\n    </tr>\n    <tr>\n      <th>30008</th>\n      <td>[]</td>\n      <td>[Mystery, Horror]</td>\n    </tr>\n    <tr>\n      <th>30009</th>\n      <td>[witch, mythology, legend, serial killer, mock...</td>\n      <td>[Horror]</td>\n    </tr>\n    <tr>\n      <th>30010</th>\n      <td>[]</td>\n      <td>[Drama, Family]</td>\n    </tr>\n    <tr>\n      <th>30011</th>\n      <td>[artist]</td>\n      <td>[Drama]</td>\n    </tr>\n  </tbody>\n</table>\n<p>30012 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(keyword_counts)[0:1000]\n",
    "\n",
    "for word_list in X['keywords']:\n",
    "    word_list[:] = [word for word in word_list if word in vocabulary]\n",
    "\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now remove the rows which have empty lists in the **'keywords'** column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "null_indices = set()\n",
    "\n",
    "for i, row in enumerate(X['keywords']):\n",
    "    if not row:\n",
    "        null_indices.add(i)\n",
    "\n",
    "X = X.drop(null_indices, axis=0).reset_index(drop=True)\n",
    "y = y.drop(null_indices, axis=0).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will make a list of unique keywords and genres to use them for column names when executing **one-hot-encoding** later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "keyword_column_names = []\n",
    "genres_column_names = []\n",
    "\n",
    "for i, row in X.iterrows():\n",
    "    for word in row.keywords:\n",
    "        if word not in keyword_column_names:\n",
    "            keyword_column_names.append(word)\n",
    "    for genre in row.genres:\n",
    "        if genre not in genres_column_names:\n",
    "            genres_column_names.append(genre)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will be using **MultiLabelBinarizer()** from sklearn to one-hot-encode **'keywords'** and **'genres'** columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       jealousy  boy  friendship  friends  rivalry  disappearance  \\\n0             0    0           0        0        0              0   \n1             0    0           0        0        0              0   \n2             0    0           0        0        0              0   \n3             0    0           0        0        0              0   \n4             0    0           0        0        0              0   \n...         ...  ...         ...      ...      ...            ...   \n26751         0    0           0        0        0              0   \n26752         0    0           0        0        0              0   \n26753         0    0           0        0        0              0   \n26754         0    0           0        0        0              0   \n26755         0    0           0        0        0              0   \n\n       based on children's book  best friend  duringcreditsstinger  \\\n0                             0            0                     0   \n1                             0            0                     0   \n2                             0            0                     0   \n3                             0            0                     0   \n4                             0            0                     0   \n...                         ...          ...                   ...   \n26751                         0            0                     0   \n26752                         0            0                     0   \n26753                         0            0                     0   \n26754                         0            0                     0   \n26755                         0            0                     0   \n\n       based on novel  ...  Horror  History  Science Fiction  Mystery  War  \\\n0                   0  ...       0        0                0        0    0   \n1                   0  ...       0        0                0        0    0   \n2                   0  ...       0        0                0        0    1   \n3                   0  ...       0        0                0        0    1   \n4                   0  ...       0        0                0        0    0   \n...               ...  ...     ...      ...              ...      ...  ...   \n26751               0  ...       0        0                0        0    0   \n26752               0  ...       0        0                0        0    0   \n26753               0  ...       0        1                0        1    0   \n26754               0  ...       0        1                0        0    0   \n26755               0  ...       0        0                0        0    0   \n\n       Foreign  Music  Documentary  Western  TV Movie  \n0            0      0            0        0         0  \n1            0      0            0        0         0  \n2            0      0            0        0         0  \n3            0      0            0        0         0  \n4            0      0            0        0         0  \n...        ...    ...          ...      ...       ...  \n26751        0      0            0        0         0  \n26752        0      0            0        0         0  \n26753        0      0            1        0         0  \n26754        0      0            0        0         0  \n26755        0      0            0        0         0  \n\n[26756 rows x 1020 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>jealousy</th>\n      <th>boy</th>\n      <th>friendship</th>\n      <th>friends</th>\n      <th>rivalry</th>\n      <th>disappearance</th>\n      <th>based on children's book</th>\n      <th>best friend</th>\n      <th>duringcreditsstinger</th>\n      <th>based on novel</th>\n      <th>...</th>\n      <th>Horror</th>\n      <th>History</th>\n      <th>Science Fiction</th>\n      <th>Mystery</th>\n      <th>War</th>\n      <th>Foreign</th>\n      <th>Music</th>\n      <th>Documentary</th>\n      <th>Western</th>\n      <th>TV Movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26751</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26752</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26753</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26754</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26755</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>26756 rows × 1020 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "X_keywords = pd.DataFrame(mlb.fit_transform(X['keywords']), columns=keyword_column_names)\n",
    "X_genres = pd.DataFrame(mlb.fit_transform(X['genres']), columns=genres_column_names)\n",
    "\n",
    "X = pd.concat([X_keywords, X_genres], axis=1)\n",
    "\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting the data\n",
    "\n",
    "Splitting the data for training and testing. For this we will be using **train_test_split** from sklearn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(26756, 1020)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=10)\n",
    "\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Balancing dataset\n",
    "\n",
    "We will also try training the model on a more balanced dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_new = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "train_0_4 = train_new[train_new.vote_average < 5]\n",
    "train_5_6 = train_new[(train_new.vote_average >= 5) & (train_new.vote_average < 7)]\n",
    "train_7_10 = train_new[train_new.vote_average >= 7]\n",
    "\n",
    "train_5_6 = train_5_6.sample(n=3389, random_state=0)\n",
    "train_7_10 = train_7_10.sample(n=3389, random_state=0)\n",
    "\n",
    "train_new = pd.concat([train_0_4, train_5_6, train_7_10]).sort_index()\n",
    "\n",
    "X_train_new = train_new.drop(columns=['vote_average'])\n",
    "y_train_new = train_new['vote_average']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "We will train a neural network using **Keras deep learning API**. We built a neural network consisting of 4 layers: input layer, **2 densely connected layers with 64 units each** and an output layer. The dense layers use **ReLU activation functions**, we are using **Adam optimization algorithm** to optimize the model. We ran 50 epochs as the model's performance plateaued around that point. The model's hyperparameters have been chosen based on trial and error testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 21.1989 - val_loss: 3.8368 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 2.9499 - val_loss: 2.2821 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.9925 - val_loss: 1.7758 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.5802 - val_loss: 1.4984 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.3414 - val_loss: 1.3288 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.2006 - val_loss: 1.2343 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.1221 - val_loss: 1.1815 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.0810 - val_loss: 1.1657 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.0571 - val_loss: 1.1526 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.0394 - val_loss: 1.1532 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 1.0261 - val_loss: 1.1441 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 1.0155 - val_loss: 1.1427 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 1.0022 - val_loss: 1.1701 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9925 - val_loss: 1.1512 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9792 - val_loss: 1.1527 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9671 - val_loss: 1.1527 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9546 - val_loss: 1.1581 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9425 - val_loss: 1.1631 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9287 - val_loss: 1.1633 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9147 - val_loss: 1.1715 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.9011 - val_loss: 1.1707 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8881 - val_loss: 1.1749 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8556 - val_loss: 1.1752 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8532 - val_loss: 1.1761 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8513 - val_loss: 1.1766 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8497 - val_loss: 1.1775 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8483 - val_loss: 1.1779 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8467 - val_loss: 1.1789 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8452 - val_loss: 1.1787 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8438 - val_loss: 1.1797 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8422 - val_loss: 1.1799 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8409 - val_loss: 1.1806 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8371 - val_loss: 1.1807 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8369 - val_loss: 1.1807 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8368 - val_loss: 1.1808 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8367 - val_loss: 1.1808 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8365 - val_loss: 1.1808 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8364 - val_loss: 1.1809 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8362 - val_loss: 1.1809 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8361 - val_loss: 1.1809 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8359 - val_loss: 1.1810 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8358 - val_loss: 1.1811 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8354 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8354 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8354 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "527/527 [==============================] - 1s 1ms/step - loss: 0.8354 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8353 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8353 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8353 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "527/527 [==============================] - 1s 2ms/step - loss: 0.8353 - val_loss: 1.1811 - lr: 1.0000e-07\n",
      "Epoch 1/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 32.4622 - val_loss: 23.2771 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 9.5689 - val_loss: 6.1392 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 3.7150 - val_loss: 4.5788 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 2.8825 - val_loss: 3.7891 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 2.4352 - val_loss: 3.3548 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 2.1581 - val_loss: 3.0868 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1.9656 - val_loss: 2.9032 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.8246 - val_loss: 2.7787 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.7142 - val_loss: 2.6899 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.6258 - val_loss: 2.6192 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.5595 - val_loss: 2.5772 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.5062 - val_loss: 2.5370 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.4633 - val_loss: 2.5085 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 2.5086 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.3991 - val_loss: 2.4977 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.3760 - val_loss: 2.4917 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1.3545 - val_loss: 2.4983 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1.3378 - val_loss: 2.4758 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1.3173 - val_loss: 2.4721 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.3028 - val_loss: 2.4850 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.2852 - val_loss: 2.4725 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.2695 - val_loss: 2.4878 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.2533 - val_loss: 2.4800 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.2365 - val_loss: 2.4999 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.2212 - val_loss: 2.4995 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1.2034 - val_loss: 2.4866 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1876 - val_loss: 2.4931 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1695 - val_loss: 2.4865 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1535 - val_loss: 2.5410 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1195 - val_loss: 2.5128 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1160 - val_loss: 2.5130 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1139 - val_loss: 2.5124 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1121 - val_loss: 2.5131 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1103 - val_loss: 2.5140 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1085 - val_loss: 2.5132 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1070 - val_loss: 2.5141 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1052 - val_loss: 2.5150 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.1034 - val_loss: 2.5162 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "266/266 [==============================] - 1s 2ms/step - loss: 1.1016 - val_loss: 2.5167 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0977 - val_loss: 2.5168 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0975 - val_loss: 2.5168 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0973 - val_loss: 2.5166 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0972 - val_loss: 2.5169 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0970 - val_loss: 2.5167 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0968 - val_loss: 2.5169 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0966 - val_loss: 2.5166 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0965 - val_loss: 2.5168 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0963 - val_loss: 2.5168 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0961 - val_loss: 2.5168 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 1.0957 - val_loss: 2.5168 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(len(keyword_column_names) + len(genres_column_names),))\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=32, epochs=50, callbacks=[tf.keras.callbacks.ReduceLROnPlateau()])\n",
    "\n",
    "model2 = tf.keras.models.clone_model(model)\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "history2 = model2.fit(X_train_new, y_train_new, validation_split=0.1, batch_size=32, epochs=50, callbacks=[tf.keras.callbacks.ReduceLROnPlateau()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model\n",
    "\n",
    "Having the model predict on the testing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 839us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[7.2592034],\n       [5.6519966],\n       [7.256482 ],\n       ...,\n       [5.813736 ],\n       [5.821364 ],\n       [5.793685 ]], dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5.5, 5.5, 7.6, ..., 6. , 5. , 4.9])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.to_numpy()\n",
    "y_preds = np.squeeze(y_preds)\n",
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results from the model that was trained on the balanced dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 798us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[7.2027473],\n       [5.5331955],\n       [8.802425 ],\n       ...,\n       [5.208526 ],\n       [6.594243 ],\n       [6.053894 ]], dtype=float32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_new = model2.predict(X_test)\n",
    "y_preds_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining our way of determining the accuracy of the models.\n",
    "For this we will be using root mean squared error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def MSE(y_target, y_pred):\n",
    "    sum = 0\n",
    "    for i in range(len(y_target)):\n",
    "        sum += (y_target[i] - y_pred[i]) ** 2\n",
    "    return sum / len(y_target)\n",
    "\n",
    "def RMSE(y_target, y_pred):\n",
    "    return math.sqrt(MSE(y_target, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finding the **accuracy** of our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for model (unbalanced) - 1.10113642947715\n",
      "RMSE for model (balanced) - 1.1727449875307518\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE for model (unbalanced) - {RMSE(y_test, y_preds)}')\n",
    "print(f'RMSE for model (balanced) - {RMSE(y_test, y_preds_new)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2e6baf65b4912df534866df4a24f335b0ddd2a79686966292e6a89b41752c6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
