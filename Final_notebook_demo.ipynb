{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project D10: KAGGLE - Movie Ratings\n",
    "\n",
    "Authors:\n",
    "- Kevin Kliimask\n",
    "- Jens JÃ¤ger\n",
    "- Taavi Eistre\n",
    "\n",
    "In this notebook we are going to analyze the dataset and train regression models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the data\n",
    "\n",
    "We will start off with importing all the necessary packages and the data.\n",
    "After looking at the data manually, we saw that 6 rows were 'broken' so to say with a lot of misaligned columns, so we decided to skip them.\n",
    "We will be using the selected columns from the report."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import math\n",
    "import ast\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('movies_metadata.csv', skiprows=[19730, 19731, 29503, 29504, 35587, 35588],\n",
    "                   usecols=['original_title', 'original_language', 'genres', 'production_companies',\n",
    "                            'production_countries', 'runtime', 'revenue', 'release_date', 'vote_average'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "First off we'll remove all the duplicate rows (movies)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'The number of movies before removing the duplicates: {len(data)}')\n",
    "data = data.drop_duplicates(ignore_index=True)\n",
    "\n",
    "print(f'The number of movies after removing the duplicates: {len(data)}')\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next off we will be converting the **JSON** formats of columns **'genres'**, **'production_companies'** and **'production_countries'** to a list format using the help of `ast.literal_eval()`,\n",
    "which helps to parse the columns' objects into the desired type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['genres'] = data['genres'].apply(lambda genres_list: [genres['name'] for genres in ast.literal_eval(genres_list)])\n",
    "\n",
    "data['production_companies'] = data['production_companies'].apply(lambda companies_list: [companies['name'] for companies in ast.literal_eval(companies_list)])\n",
    "\n",
    "data['production_countries'] = data['production_countries'].apply(lambda countries_list: [countries['name'] for countries in ast.literal_eval(countries_list)])\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we will remove all the movies that have:\n",
    "- No genres\n",
    "- No production countries\n",
    "- No production companies\n",
    "- 0 runtime\n",
    "- 0 vote_average\n",
    "- NaN values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'The number of movies before removing all of the mentioned movies above: {len(data)}')\n",
    "\n",
    "data = data.dropna()\n",
    "data = data[(data.runtime > 0) & (data.vote_average > 0) & (data.genres.str.len() > 0) & (data.production_companies.str.len() > 0) & (data.production_countries.str.len() > 0)]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(f'The number of movies after removing all of the mentioned movies above: {len(data)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finding the **total number** and **frequency** of genres, companies and countries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genres_dict = {}\n",
    "companies_dict = {}\n",
    "countries_dict = {}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    for genre in row['genres']:\n",
    "        genres_dict[genre] = genres_dict.get(genre, 0) + 1\n",
    "\n",
    "    for company in row['production_companies']:\n",
    "        companies_dict[company] = companies_dict.get(company, 0) + 1\n",
    "\n",
    "    for country in row['production_countries']:\n",
    "        countries_dict[country] = countries_dict.get(country, 0) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'The number of genres: {len(genres_dict)}')\n",
    "print(f'The number of production companies: {len(companies_dict)}')\n",
    "print(f'The number of production countries: {len(countries_dict)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After seeing that there are **too many** production companies, we decided not to use them on the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring our data\n",
    "\n",
    "Now that we have cleaned the data, let's have a look at what interesting we can find from what remains."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14976/2426922694.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, we'll look at the top 10 highest rated movies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'The number of movies with a rating of 10: {len(data[data.vote_average == 10])}')\n",
    "data.sort_values(by=['vote_average'], ascending=False).head(10)[['original_title', 'vote_average']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will see the **frequency** histogram of the top 25 original languages of movies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "language_freq = data['original_language'].value_counts()[:25]\n",
    "language_freq.plot(kind='bar', figsize=(12, 5), rot=45, xlabel='Original language', ylabel='Number of movies', title='Original language frequency histogram')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next up, runtime **frequency** histogram."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['runtime'].hist(bins=100, range=[0, 300])\n",
    "plt.title('Runtime frequency histogram')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Number of movies')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The vote average (rating) **frequency** histogram."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['vote_average'].hist(bins=10, range=[0, 10])\n",
    "plt.title('Vote average frequency histogram')\n",
    "plt.xlabel('Vote average')\n",
    "plt.ylabel('Number of movies')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's see the **relative frequency** histogram of genres."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genres_dict = dict(sorted(genres_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "total_number = 0\n",
    "for freq in genres_dict.values():\n",
    "    total_number += freq\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(range(len(genres_dict)), [freq / total_number for freq in genres_dict.values()], align='center')\n",
    "plt.xticks(range(len(genres_dict)), list(genres_dict.keys()), rotation=45)\n",
    "plt.ylabel('Relative frequency of genres')\n",
    "plt.title('Relative frequency histogram of genres')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **relative frequency** histogram of the top 25 production companies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "companies_dict = dict(sorted(companies_dict.items(), key=lambda x: x[1], reverse=True)[:25])\n",
    "total_number = 0\n",
    "for freq in companies_dict.values():\n",
    "    total_number += freq\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(list(companies_dict.keys()), [freq / total_number for freq in companies_dict.values()], align='center', orientation='horizontal')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Relative frequency of production companies')\n",
    "plt.title('Production companies relative frequency histogram')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And finally, the **relative frequency** histogram of the top 25 production countries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "countries_dict = dict(sorted(countries_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "total_number = 0\n",
    "for freq in list(countries_dict.values())[:25]:\n",
    "    total_number += freq\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(list(countries_dict.keys())[:25], [freq / total_number for freq in list(countries_dict.values())[:25]], align='center')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Relative frequency of production countries')\n",
    "plt.title('Production countries relative frequency histogram')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The top 15 mean yearly revenues."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['release_date'] = data['release_date'].apply(lambda date: str(date)[:4])\n",
    "\n",
    "yearly_revenues = data.groupby('release_date')['revenue'].mean().sort_values(ascending=False)[:15]\n",
    "yearly_revenues = yearly_revenues.apply(lambda x: round(x / 1_000_000, 2))\n",
    "\n",
    "yearly_revenues.plot(kind='bar', figsize=(10, 5), rot=45, title='Top 15 mean yearly revenue', xlabel='Release year', ylabel='Yearly mean revenue (mil)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Starting with the model\n",
    "## Preparing data\n",
    "\n",
    "We will drop 'original_title', 'production_companies', 'release_date' and 'revenue', as these are not going to be used in the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.drop(columns=['original_title', 'production_companies', 'release_date', 'revenue'])\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we will use pd.get_dummies to one-hot-encode 'original_language' column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['original_language'])\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will be using MultiLabelBinarizer() from sklearn to one-hot-encode 'genres' and 'production_countries' columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genres_columns = [genre for genre in genres_dict.keys()]\n",
    "\n",
    "countries_columns = [country for country in countries_dict.keys()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "genres_list = pd.DataFrame(mlb.fit_transform(data['genres']), columns=genres_columns)\n",
    "\n",
    "countries_list = pd.DataFrame(mlb.fit_transform(data['production_countries']), columns=countries_columns)\n",
    "\n",
    "data = pd.concat([data.drop(columns=['genres', 'production_countries']), genres_list, countries_list], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting the data\n",
    "\n",
    "Splitting the data for training and testing. For this we will be using train_test_split from sklearn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = data.drop(columns=['vote_average'])\n",
    "y = data['vote_average']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n",
    "\n",
    "print('Features data shape:')\n",
    "print(X_train.shape)\n",
    "print('Values data shape:')\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will be trying to train the model on two different training data. The first one will be the full training dataset and the second one will be a more balanced one, where movie ratings (vote averages) try to be in equal number (same number of 2's as there are 4's for example)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_new = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "train_0_4 = train_new[train_new.vote_average < 5]\n",
    "train_5_6 = train_new[(train_new.vote_average >= 5) & (train_new.vote_average < 7)]\n",
    "train_7_10 = train_new[train_new.vote_average >= 7]\n",
    "\n",
    "print(f'Length of movies with 0-4: {len(train_0_4)}')\n",
    "print(f'Length of movies with 5-6: {len(train_5_6)}')\n",
    "print(f'Length of movies with 7-10: {len(train_7_10)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_5_6 = train_5_6.sample(n=3389, random_state=0)\n",
    "train_7_10 = train_7_10.sample(n=3389, random_state=0)\n",
    "\n",
    "train_new = pd.concat([train_0_4, train_5_6, train_7_10]).sort_index()\n",
    "\n",
    "X_train_new = train_new.drop(columns=['vote_average'])\n",
    "y_train_new = train_new['vote_average']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Length of original training data: {len(X_train)}')\n",
    "print(f'Length of more balanced training data: {len(X_train_new)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining our way of determining the accuracy of the models.\n",
    "For this we will be using root mean squared error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def MSE(y_target, y_pred):\n",
    "    sum = 0\n",
    "    for i in range(len(y_target)):\n",
    "        sum += (y_target[i] - y_pred[i]) ** 2\n",
    "    return sum / len(y_target)\n",
    "\n",
    "def RMSE(y_target, y_pred):\n",
    "    return math.sqrt(MSE(y_target, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the models\n",
    "\n",
    "We will be trying Linear Regression, Ridge Regression and Lasso Regression for this dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_1 = LinearRegression()\n",
    "linear_2 = LinearRegression()\n",
    "\n",
    "ridge_1 = Ridge()\n",
    "ridge_2 = Ridge()\n",
    "\n",
    "lasso_1 = Lasso()\n",
    "lasso_2 = Lasso()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_1 = linear_1.fit(X_train, y_train)\n",
    "linear_2 = linear_2.fit(X_train_new, y_train_new)\n",
    "\n",
    "ridge_1 = ridge_1.fit(X_train, y_train)\n",
    "ridge_2 = ridge_2.fit(X_train_new, y_train_new)\n",
    "\n",
    "lasso_1 = lasso_1.fit(X_train, y_train)\n",
    "lasso_2 = lasso_2.fit(X_train_new, y_train_new)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the models\n",
    "\n",
    "Having the new models predict on the testing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_1_pred = linear_1.predict(X_test)\n",
    "linear_2_pred = linear_2.predict(X_test)\n",
    "\n",
    "ridge_1_pred = ridge_1.predict(X_test)\n",
    "ridge_2_pred = ridge_2.predict(X_test)\n",
    "\n",
    "lasso_1_pred = lasso_1.predict(X_test)\n",
    "lasso_2_pred = lasso_2.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finding the accuracy of our new models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'RMSE for LR (unbalanced) - {RMSE(y_test.to_numpy(), linear_1_pred)}')\n",
    "print(f'RMSE for LR (more balanced) - {RMSE(y_test.to_numpy(), linear_2_pred)}\\n')\n",
    "\n",
    "print(f'RMSE for Ridge (unbalanced) - {RMSE(y_test.to_numpy(), ridge_1_pred)}')\n",
    "print(f'RMSE for Ridge (more balanced) - {RMSE(y_test.to_numpy(), ridge_2_pred)}\\n')\n",
    "\n",
    "print(f'RMSE for Lasso (unbalanced) - {RMSE(y_test.to_numpy(), lasso_1_pred)}')\n",
    "print(f'RMSE for Lasso (more balanced) - {RMSE(y_test.to_numpy(), lasso_2_pred)}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, Ridge Regression performed the best on our test set with a root mean squared error of about 1.09."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
